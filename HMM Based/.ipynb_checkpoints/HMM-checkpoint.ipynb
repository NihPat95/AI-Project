{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"dataset/warpeace.txt\"\n",
    "sequenceLength = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = []\n",
    "tempMapping = {}\n",
    "mapping = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', ',', 'thought', 'alice', 'without', 'pictures', 'or', 'conversations', '?', '.', 'alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', '.']\n"
     ]
    }
   ],
   "source": [
    "with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "    rawText = f.read().lower()\n",
    "wordList = word_tokenize(rawText)\n",
    "print(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addItemToMapping(history, word):\n",
    "    while len(history) > 0:\n",
    "        first = tuple(history)\n",
    "        if first in tempMapping:\n",
    "            if word in tempMapping[first]:\n",
    "                tempMapping[first][word] = tempMapping[first][word] + 1.0\n",
    "            else:\n",
    "                tempMapping[first][word] = 1.0\n",
    "        else:\n",
    "            tempMapping[first] = {}\n",
    "            tempMapping[first][word] = 1.0\n",
    "        history = history[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build():\n",
    "    for i in range(sequenceLength,len(wordList)-1):\n",
    "        history = wordList[i-sequenceLength:i]\n",
    "        follow = wordList[i+1]\n",
    "        addItemToMapping(history, follow)\n",
    "    print(tempMapping)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('alice',): {'beginning': 2.0, 'pictures': 1.0}, ('was',): {'to': 2.0, ',': 1.0}, ('beginning',): {'get': 2.0}, ('to',): {'very': 2.0, ':': 1.0}, ('get',): {'tired': 2.0}, ('very',): {'of': 1.0, '.': 1.0}, ('tired',): {'sitting': 1.0}, ('of',): {'by': 1.0, 'nothing': 1.0, 'book': 1.0}, ('sitting',): {'her': 1.0}, ('by',): {'sister': 1.0}, ('her',): {'on': 1.0, 'was': 1.0}, ('sister',): {'the': 1.0, 'reading': 1.0}, ('on',): {'bank': 1.0}, ('the',): {',': 1.0, 'her': 1.0, 'of': 1.0}, ('bank',): {'and': 1.0}, (',',): {'of': 1.0, 'it': 1.0, 'what': 1.0, 'alice': 1.0}, ('and',): {'having': 1.0, 'is': 1.0}, ('having',): {'to': 1.0}, ('nothing',): {'do': 1.0}, ('do',): {'once': 1.0}, (':',): {'or': 1.0}, ('once',): {'twice': 1.0}, ('or',): {'she': 1.0, 'in': 1.0, '?': 1.0}, ('twice',): {'had': 1.0}, ('she',): {'peeped': 1.0}, ('had',): {'into': 1.0, 'pictures': 1.0}, ('peeped',): {'the': 1.0}, ('into',): {'book': 1.0}, ('book',): {'sister': 1.0, 'thought': 1.0}, ('reading',): {'but': 1.0}, ('but',): {'had': 1.0}, ('it',): {'no': 1.0, 'and': 1.0}, ('no',): {'or': 1.0}, ('pictures',): {'conversations': 2.0}, ('conversations',): {'it': 1.0, '.': 1.0}, ('in',): {',': 1.0}, ('what',): {'the': 1.0}, ('is',): {'use': 1.0}, ('use',): {'a': 1.0}, ('a',): {',': 1.0}, ('thought',): {'without': 1.0}, ('without',): {'or': 1.0}, ('?',): {'alice': 1.0}, ('.',): {'was': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize():\n",
    "    for first, follow in iter(tempMapping.items()):\n",
    "        total = sum(follow.values())\n",
    "        mapping[first] = dict([(k,v/total) for k,v in iter(follow.items())])\n",
    "        \n",
    "    print (mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('alice',): {'beginning': 0.6666666666666666, 'pictures': 0.3333333333333333}, ('was',): {'to': 0.6666666666666666, ',': 0.3333333333333333}, ('beginning',): {'get': 1.0}, ('to',): {'very': 0.6666666666666666, ':': 0.3333333333333333}, ('get',): {'tired': 1.0}, ('very',): {'of': 0.5, '.': 0.5}, ('tired',): {'sitting': 1.0}, ('of',): {'by': 0.3333333333333333, 'nothing': 0.3333333333333333, 'book': 0.3333333333333333}, ('sitting',): {'her': 1.0}, ('by',): {'sister': 1.0}, ('her',): {'on': 0.5, 'was': 0.5}, ('sister',): {'the': 0.5, 'reading': 0.5}, ('on',): {'bank': 1.0}, ('the',): {',': 0.3333333333333333, 'her': 0.3333333333333333, 'of': 0.3333333333333333}, ('bank',): {'and': 1.0}, (',',): {'of': 0.25, 'it': 0.25, 'what': 0.25, 'alice': 0.25}, ('and',): {'having': 0.5, 'is': 0.5}, ('having',): {'to': 1.0}, ('nothing',): {'do': 1.0}, ('do',): {'once': 1.0}, (':',): {'or': 1.0}, ('once',): {'twice': 1.0}, ('or',): {'she': 0.3333333333333333, 'in': 0.3333333333333333, '?': 0.3333333333333333}, ('twice',): {'had': 1.0}, ('she',): {'peeped': 1.0}, ('had',): {'into': 0.5, 'pictures': 0.5}, ('peeped',): {'the': 1.0}, ('into',): {'book': 1.0}, ('book',): {'sister': 0.5, 'thought': 0.5}, ('reading',): {'but': 1.0}, ('but',): {'had': 1.0}, ('it',): {'no': 0.5, 'and': 0.5}, ('no',): {'or': 1.0}, ('pictures',): {'conversations': 1.0}, ('conversations',): {'it': 0.5, '.': 0.5}, ('in',): {',': 1.0}, ('what',): {'the': 1.0}, ('is',): {'use': 1.0}, ('use',): {'a': 1.0}, ('a',): {',': 1.0}, ('thought',): {'without': 1.0}, ('without',): {'or': 1.0}, ('?',): {'alice': 1.0}, ('.',): {'was': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSentence():\n",
    "    sent = \"\"\n",
    "    lengthToGenerate = 10\n",
    "    curr = \"\"\n",
    "    inputSentence = \"Alice was getting\".tolower()\n",
    "    sent = sent + curr\n",
    "    prevList = word_tokenize(inputSentence)\n",
    "    for i in range(1,lengthToGenerate):\n",
    "        curr = next(prevList)\n",
    "        prevList.append(curr)\n",
    "        sent = sent + curr\n",
    "    \n",
    "    return sent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next(previous):\n",
    "    sum = 0.0\n",
    "    retval = \"\"\n",
    "    index = random.random()\n",
    "    # Shorten prevList until it's in mapping\n",
    "    while toHashKey(prevList) not in mapping:\n",
    "        prevList.pop(0)\n",
    "    # Get a random word from the mapping, given prevList\n",
    "    for k, v in mapping[toHashKey(prevList)].iteritems():\n",
    "        sum += v\n",
    "        if sum >= index and retval == \"\":\n",
    "            retval = k\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
