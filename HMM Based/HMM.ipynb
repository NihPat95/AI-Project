{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import random\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import operator\n",
    "import bisect\n",
    "from unidecode import unidecode\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = \"dataset/test.txt\"\n",
    "word_split_pattern = re.compile(r\"\\s+\")\n",
    "sequenceLength = 2\n",
    "BEGIN = \"___BEGIN__\"\n",
    "END = \"___END__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordList = []\n",
    "tempMapping = {}\n",
    "begin_cumdist= None\n",
    "begin_choices = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentence_split(text):\n",
    "    potential_end_pat = re.compile(r\"\".join([\n",
    "        r\"([\\w\\.'’&\\]\\)]+[\\.\\?!])\", # A word that ends with punctuation\n",
    "        r\"([‘’“”'\\\"\\)\\]]*)\", # Followed by optional quote/parens/etc\n",
    "        r\"(\\s+(?![a-z\\-–—]))\", # Followed by whitespace + non-(lowercase or dash)\n",
    "        ]), re.U)\n",
    "    dot_iter = re.finditer(potential_end_pat, text)\n",
    "    end_indices = [ (x.start() + len(x.group(1)) + len(x.group(2)))\n",
    "        for x in dot_iter]\n",
    "    spans = zip([None] + end_indices, end_indices + [None])\n",
    "    sentences = [ text[start:end].strip() for start, end in spans ]\n",
    "   \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def word_split(sentence):\n",
    "    return re.split(word_split_pattern, sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_sentence_input(sentence):\n",
    "    if len(sentence.strip()) == 0: return False\n",
    "    reject_pat = re.compile(r\"(^')|('$)|\\s'|'\\s|[\\\"(\\(\\)\\[\\])]\")\n",
    "    # Decode unicode, mainly to normalize fancy quotation marks\n",
    "    if sentence.__class__.__name__ == \"str\": # pragma: no cover\n",
    "        decoded = sentence\n",
    "    else: # pragma: no cover\n",
    "        decoded = unidecode(sentence)\n",
    "    # Sentence shouldn't contain problematic characters\n",
    "    if re.search(reject_pat, decoded): \n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_corpus(text):\n",
    "    if isinstance(text, str):\n",
    "        sentences = sentence_split(text)\n",
    "    else:\n",
    "        sentences = []\n",
    "        for line in text:\n",
    "            sentences += sentence_split(line)\n",
    "    \n",
    "    passing = filter(test_sentence_input, sentences)\n",
    "    \n",
    "    sentences = map(word_split, passing)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total number of sentences in the corpus: ', 5)\n"
     ]
    }
   ],
   "source": [
    "with io.open(filename, 'r', encoding=\"utf8\") as f:\n",
    "    rawText = f.read().lower()\n",
    "\n",
    "sentence_list = sent_tokenize(rawText)\n",
    "print(\"Total number of sentences in the corpus: \",len(sentence_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordList = generate_corpus(sentence_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('___BEGIN__', '___BEGIN__'): {u'behind': 1,\n",
       "  u'under': 1,\n",
       "  u'we': 1,\n",
       "  u'will': 2},\n",
       " ('___BEGIN__', u'behind'): {u'him,': 1},\n",
       " ('___BEGIN__', u'under'): {u'the': 1},\n",
       " ('___BEGIN__', u'we'): {u'have': 1},\n",
       " ('___BEGIN__', u'will'): {u'made': 1, u'threaded': 1},\n",
       " (u'a', u'sentinel'): {u'tree.': 1},\n",
       " (u'a', u'thicket,'): {u'then': 1},\n",
       " (u'a', u'winner.'): {'___END__': 1},\n",
       " (u'and', u'hidden'): {u'roots': 1},\n",
       " (u'and', u'muddy,'): {u'slick': 1},\n",
       " (u'and', u'muttered'): {u'curses': 1},\n",
       " (u'and', u'tugged'): {u'on': 1},\n",
       " (u'as', u'he'): {u'climbed.': 1},\n",
       " (u'as', u'reaching'): {u'branches': 1},\n",
       " (u'at', u'his'): {u'longsword': 1},\n",
       " (u'behind', u'him,'): {u'he': 1},\n",
       " (u'branches', u'grabbed'): {u'at': 1},\n",
       " (u'crust', u'of'): {u'snow,': 1},\n",
       " (u'curses', u'as'): {u'reaching': 1},\n",
       " (u'damp', u'and'): {u'muddy,': 1},\n",
       " (u'footing,', u'with'): {u'rocks': 1},\n",
       " (u'found', u'his'): {u'vantage': 1},\n",
       " (u'grabbed', u'at'): {u'his': 1},\n",
       " (u'ground', u'was'): {u'damp': 1},\n",
       " (u'had', u'found'): {u'his': 1},\n",
       " (u'have', u'a'): {u'winner.': 1},\n",
       " (u'he', u'climbed.'): {'___END__': 1},\n",
       " (u'he', u'had'): {u'found': 1},\n",
       " (u'he', u'heard'): {u'the': 1},\n",
       " (u'heard', u'the'): {u'soft': 1},\n",
       " (u'hidden', u'roots'): {u'to': 1},\n",
       " (u'him,', u'he'): {u'heard': 1},\n",
       " (u'his', u'longsword'): {u'and': 1},\n",
       " (u'his', u'splendid'): {u'sable': 1},\n",
       " (u'his', u'vantage'): {u'point': 1},\n",
       " (u'leaves,', u'and'): {u'muttered': 1},\n",
       " (u'longsword', u'and'): {u'tugged': 1},\n",
       " (u'lordling\\u2019s', u'ringmail,'): {u'the': 1},\n",
       " (u'low', u'ridge'): {u'where': 1},\n",
       " (u'made', u'no'): {u'sound': 1},\n",
       " (u'metallic', u'slither'): {u'of': 1},\n",
       " (u'muddy,', u'slick'): {u'footing,': 1},\n",
       " (u'muttered', u'curses'): {u'as': 1},\n",
       " (u'no', u'sound'): {u'as': 1},\n",
       " (u'of', u'leaves,'): {u'and': 1},\n",
       " (u'of', u'snow,'): {u'the': 1},\n",
       " (u'of', u'the'): {u'lordling\\u2019s': 1},\n",
       " (u'on', u'his'): {u'splendid': 1},\n",
       " (u'point', u'under'): {u'a': 1},\n",
       " (u'reaching', u'branches'): {u'grabbed': 1},\n",
       " (u'ridge', u'where'): {u'he': 1},\n",
       " (u'ringmail,', u'the'): {u'rustle': 1},\n",
       " (u'rocks', u'and'): {u'hidden': 1},\n",
       " (u'roots', u'to'): {u'trip': 1},\n",
       " (u'rustle', u'of'): {u'leaves,': 1},\n",
       " (u'sable', u'cloak.'): {'___END__': 1},\n",
       " (u'sentinel', u'tree.'): {'___END__': 1},\n",
       " (u'slick', u'footing,'): {u'with': 1},\n",
       " (u'slither', u'of'): {u'the': 1},\n",
       " (u'slope', u'to'): {u'the': 1},\n",
       " (u'snow,', u'the'): {u'ground': 1},\n",
       " (u'soft', u'metallic'): {u'slither': 1},\n",
       " (u'sound', u'as'): {u'he': 1},\n",
       " (u'splendid', u'sable'): {u'cloak.': 1},\n",
       " (u'started', u'up'): {u'the': 1},\n",
       " (u'the', u'ground'): {u'was': 1},\n",
       " (u'the', u'lordling\\u2019s'): {u'ringmail,': 1},\n",
       " (u'the', u'low'): {u'ridge': 1},\n",
       " (u'the', u'rustle'): {u'of': 1},\n",
       " (u'the', u'slope'): {u'to': 1},\n",
       " (u'the', u'soft'): {u'metallic': 1},\n",
       " (u'the', u'thin'): {u'crust': 1},\n",
       " (u'their', u'way'): {u'through': 1},\n",
       " (u'then', u'started'): {u'up': 1},\n",
       " (u'thicket,', u'then'): {u'started': 1},\n",
       " (u'thin', u'crust'): {u'of': 1},\n",
       " (u'threaded', u'their'): {u'way': 1},\n",
       " (u'through', u'a'): {u'thicket,': 1},\n",
       " (u'to', u'the'): {u'low': 1},\n",
       " (u'to', u'trip'): {u'you': 1},\n",
       " (u'trip', u'you'): {u'up.': 1},\n",
       " (u'tugged', u'on'): {u'his': 1},\n",
       " (u'under', u'a'): {u'sentinel': 1},\n",
       " (u'under', u'the'): {u'thin': 1},\n",
       " (u'up', u'the'): {u'slope': 1},\n",
       " (u'vantage', u'point'): {u'under': 1},\n",
       " (u'was', u'damp'): {u'and': 1},\n",
       " (u'way', u'through'): {u'a': 1},\n",
       " (u'we', u'have'): {u'a': 1},\n",
       " (u'where', u'he'): {u'had': 1},\n",
       " (u'will', u'made'): {u'no': 1},\n",
       " (u'will', u'threaded'): {u'their': 1},\n",
       " (u'with', u'rocks'): {u'and': 1},\n",
       " (u'you', u'up.'): {'___END__': 1}}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build():\n",
    "    print(len(wordList))\n",
    "    for sentence in wordList:\n",
    "        items = ([ BEGIN ] * sequenceLength) + sentence + [ END ] \n",
    "        for i in range(len(sentence) + 1):\n",
    "            state = tuple(items[i:i+sequenceLength])\n",
    "            follow = items[i+sequenceLength]\n",
    "            if state not in tempMapping:\n",
    "                tempMapping[state] = {}\n",
    "            if follow not in tempMapping[state]:\n",
    "                tempMapping[state][follow] = 0\n",
    "\n",
    "            tempMapping[state][follow] += 1\n",
    "    return tempMapping    \n",
    "build() \n",
    "#print(tempMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def accumulate(iterable, func=operator.add):\n",
    "    \"\"\"\n",
    "    Cumulative calculations. (Summation, by default.)\n",
    "    Via: https://docs.python.org/3/library/itertools.html#itertools.accumulate\n",
    "    \"\"\"\n",
    "    it = iter(iterable)\n",
    "    total = next(it)\n",
    "    yield total\n",
    "    for element in it:\n",
    "        total = func(total, element)\n",
    "        yield total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(state):\n",
    "    if state == tuple([BEGIN]* sequenceLength):\n",
    "        begin_state = tuple([ BEGIN ] * sequenceLength)\n",
    "        choices, weights = zip(*tempMapping[begin_state].items())\n",
    "        \n",
    "    else:\n",
    "        choices, weights = zip(*tempMapping[state].items())\n",
    "    cumdist = list(accumulate(weights))\n",
    "    r = random.random() * cumdist[-1]\n",
    "    selection = choices[bisect.bisect(cumdist, r)]\n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under the thin crust of snow, the ground was damp and muddy, slick footing, with rocks and hidden roots to trip you up. \n"
     ]
    }
   ],
   "source": [
    "def gen(init_state=None):\n",
    "    state = init_state or (BEGIN,) * sequenceLength\n",
    "    while True:\n",
    "        next_word = move(state)\n",
    "        if next_word == END: break\n",
    "        #print(\"next word\",next_word)\n",
    "        yield next_word\n",
    "        state = tuple(state[1:]) + (next_word,)\n",
    "    \n",
    "# prefix=\"we have\"\n",
    "# op = gen(tuple([x for x in prefix.split(\" \")]))\n",
    "# result=prefix + \" \"\n",
    "op = gen(None)\n",
    "result=\"\"\n",
    "\n",
    "for w in op:\n",
    "    result = result + w + \" \"\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
